{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing Basic libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model, naive_bayes\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "import bokeh as bk\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import plotly\n",
    "import chart_studio.plotly as py\n",
    "from chart_studio.plotly import plot, iplot \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objects as go\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import pybaseball as pyb\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from pybaseball import statcast\n",
    "from pybaseball import statcast_pitcher\n",
    "from pybaseball import statcast_batter\n",
    "from pybaseball import statcast_pitcher_exitvelo_barrels\n",
    "from pybaseball import statcast_batter_exitvelo_barrels\n",
    "from pybaseball import statcast_batter_expected_stats\n",
    "from pybaseball import statcast_pitcher_expected_stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pwlf as pwlf\n",
    "#import matplotlib.backends\n",
    "import matplotlib as mpl\n",
    "import joblib\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from test import keras\n",
    "from keras.models import Sequential\n",
    "#dense\n",
    "from keras.layers import Dense\n",
    "#adam\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.read_csv(\"/Users/johndavis/Desktop/Desktop_2/Statcast_ALL_TIME.csv\",low_memory=False)\n",
    "df_2023 = pd.read_csv(\"/Users/johndavis/Desktop/Desktop_2/MLB_2023_FULL.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiply pfx_z\tpfx_x by 12 to get inches\n",
    "df_2022['pfx_x'] = df_2022['pfx_x']*12\n",
    "df_2022['pfx_z'] = df_2022['pfx_z']*12\n",
    "df_2023['pfx_x'] = df_2023['pfx_x']*12\n",
    "df_2023['pfx_z'] = df_2023['pfx_z']*12\n",
    "\n",
    "\n",
    "#multiply pfx_x by -1 to get pitchers view\n",
    "df_2022['pfx_x'] = df_2022['pfx_x']*-1\n",
    "df_2023['pfx_x'] = df_2023['pfx_x']*-1\n",
    "\n",
    "df_2022.rename(columns={'game_date': 'Date', 'player_name':'Pitcher','p_throws':'Hand','pitch_type':'TaggedPitchType','release_speed':'RelSpeed','release_pos_x':'RelSide','release_pos_z':'RelHeight','pfx_x':'HorzBreak','pfx_z':'InducedVertBreak','release_extension':'Extension','plate_x': 'PlateLocSide','plate_z': 'PlateLocHeight', 'release_spin_rate':'SpinRate'},inplace=True)\n",
    "df_2023.rename(columns={'game_date': 'Date', 'player_name':'Pitcher','p_throws':'Hand','pitch_type':'TaggedPitchType','release_speed':'RelSpeed','release_pos_x':'RelSide','release_pos_z':'RelHeight','pfx_x':'HorzBreak','pfx_z':'InducedVertBreak','release_extension':'Extension','plate_x': 'PlateLocSide','plate_z': 'PlateLocHeight','release_spin_rate':'SpinRate'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if Event is == NaN fill with description\n",
    "df_2022['events'].fillna(df_2022['description'], inplace=True)\n",
    "df_2023['events'].fillna(df_2023['description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2023 Pitcher\tTaggedPitchType\tRelSpeed\trelease_spin_rate\tInducedVertBreak\tHorzBreak\tRelSide\tRelHeight\tExtension\t\n",
    "df_2022 = df_2022[['Pitcher','Hand','TaggedPitchType','events','description','RelSpeed','SpinRate','InducedVertBreak','HorzBreak','RelSide','RelHeight','Extension','PlateLocSide','PlateLocHeight','batter','launch_speed','launch_angle','hit_distance_sc','delta_run_exp']]\n",
    "df_2023 = df_2023[['Pitcher','Hand','TaggedPitchType','events','description','RelSpeed','SpinRate','InducedVertBreak','HorzBreak','RelSide','RelHeight','Extension','PlateLocSide','PlateLocHeight','batter','launch_speed','launch_angle','hit_distance_sc','delta_run_exp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run values \n",
    "field_out = -0.1955687665555\n",
    "force_out = -0.1955687665555\n",
    "other_out = -0.1955687665555\n",
    "fielders_choice_out = -0.1955687665555\n",
    "called_strike = -0.118124935770601\n",
    "swinging_strike = -0.118124935770601\n",
    "ball = 0.0636883289483747\n",
    "foul = -0.0380502742575014\n",
    "single = 0.467292970729251\n",
    "double = 0.766083122898271\n",
    "triple = 1.05755624961515\n",
    "home_run = 1.374328827219\n",
    "strikeout = -0.118124935770601\n",
    "fielders_choice = -0.1955687665555\n",
    "hit_by_pitch = 0.0636883289483747\n",
    "walk = 0.0636883289483747\n",
    "field_error = -0.1955687665555\n",
    "walk = 0.0636883289483747\n",
    "sac_fly = 0.0636883289483747\n",
    "double_play = -0.1955687665555\n",
    "wild_pitch =0.0636883289483747\n",
    "blocked_ball = 0.0636883289483747\n",
    "grounded_into_double_play = -0.1955687665555\n",
    "foul_bunt = -0.0380502742575014\n",
    "foul_tip = -0.0380502742575014\n",
    "sac_bunt_double_play = -0.1955687665555\n",
    "swinging_strike_blocked = -0.118124935770601\n",
    "missed_bunt = -0.118124935770601\n",
    "sac_bunt = 0.0636883289483747\n",
    "pitchout = 0\n",
    "caught_stealing_2b = 0\n",
    "bunt_foul_tip = -0.0380502742575014\n",
    "strikeout_double_play = -0.118124935770601\n",
    "pickoff_3b = 0 \n",
    "catcher_interf = 0\n",
    "caught_stealing_3b = 0 \n",
    "pickoff_caught_stealing_2b = 0\n",
    "triple_play = -0.118124935770601\n",
    "caught_stealing_home = 0 \n",
    "sac_fly_double_play = -0.1955687665555\n",
    "pickoff_1b = 0 \n",
    "pickoff_caught_stealing_home = 0\n",
    "pickoff_caught_stealing_3b = 0 \n",
    "game_advisory = 0\n",
    "pickoff_2b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022['RunValue'] = df_2022['events'].map({'field_out':field_out,'force_out':force_out,'other_out':other_out,'fielders_choice_out':fielders_choice_out,'called_strike':called_strike,'swinging_strike':swinging_strike,'ball':ball,'foul':foul,'single':single,'double':double,'triple':triple,'home_run':home_run,'strikeout':strikeout,'fielders_choice':fielders_choice,'hit_by_pitch':hit_by_pitch,'walk':walk,'field_error':field_error,'walk':walk,'sac_fly':sac_fly,'double_play':double_play,'wild_pitch':wild_pitch,'blocked_ball':blocked_ball,'grounded_into_double_play':grounded_into_double_play,'foul_bunt':foul_bunt,'foul_tip':foul_tip,'sac_bunt_double_play':sac_bunt_double_play,'swinging_strike_blocked':swinging_strike_blocked,'missed_bunt':missed_bunt,'sac_bunt':sac_bunt,'pitchout':pitchout,'caught_stealing_2b':caught_stealing_2b,'bunt_foul_tip':bunt_foul_tip,'strikeout_double_play':strikeout_double_play,'pickoff_3b':pickoff_3b,'catcher_interf':catcher_interf,'caught_stealing_3b':caught_stealing_3b,'pickoff_caught_stealing_2b':pickoff_caught_stealing_2b,'triple_play':triple_play,'caught_stealing_home':caught_stealing_home,'sac_fly_double_play':sac_fly_double_play,'pickoff_1b':pickoff_1b,'pickoff_caught_stealing_home':pickoff_caught_stealing_home,'pickoff_caught_stealing_3b':pickoff_caught_stealing_3b,'game_advisory':game_advisory,'pickoff_2b':pickoff_2b})\n",
    "df_2023['RunValue'] = df_2023['events'].map({'field_out':field_out,'force_out':force_out,'other_out':other_out,'fielders_choice_out':fielders_choice_out,'called_strike':called_strike,'swinging_strike':swinging_strike,'ball':ball,'foul':foul,'single':single,'double':double,'triple':triple,'home_run':home_run,'strikeout':strikeout,'fielders_choice':fielders_choice,'hit_by_pitch':hit_by_pitch,'walk':walk,'field_error':field_error,'walk':walk,'sac_fly':sac_fly,'double_play':double_play,'wild_pitch':wild_pitch,'blocked_ball':blocked_ball,'grounded_into_double_play':grounded_into_double_play,'foul_bunt':foul_bunt,'foul_tip':foul_tip,'sac_bunt_double_play':sac_bunt_double_play,'swinging_strike_blocked':swinging_strike_blocked,'missed_bunt':missed_bunt,'sac_bunt':sac_bunt,'pitchout':pitchout,'caught_stealing_2b':caught_stealing_2b,'bunt_foul_tip':bunt_foul_tip,'strikeout_double_play':strikeout_double_play,'pickoff_3b':pickoff_3b,'catcher_interf':catcher_interf,'caught_stealing_3b':caught_stealing_3b,'pickoff_caught_stealing_2b':pickoff_caught_stealing_2b,'triple_play':triple_play,'caught_stealing_home':caught_stealing_home,'sac_fly_double_play':sac_fly_double_play,'pickoff_1b':pickoff_1b,'pickoff_caught_stealing_home':pickoff_caught_stealing_home,'pickoff_caught_stealing_3b':pickoff_caught_stealing_3b,'game_advisory':game_advisory,'pickoff_2b':pickoff_2b})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all Nan Events with Descriptions\n",
    "df_2022['events'].fillna(df_2022['description'], inplace=True)\n",
    "df_2023['events'].fillna(df_2023['description'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter only balls in play == hit_into_play\n",
    "df_2022_hit_into_play = df_2022[df_2022['description'] == 'hit_into_play']\n",
    "df_2023_hit_into_play = df_2023[df_2023['description'] == 'hit_into_play']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_hit_into_play = df_2022[df_2022['description'] != 'hit_into_play']\n",
    "df_not_hit_into_play_2023 = df_2023[df_2023['description'] != 'hit_into_play']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict run value based on launch_speed','launch_angle','hit_distanc_sc'\n",
    "X = df_2022_hit_into_play[['launch_speed','launch_angle','hit_distance_sc']]\n",
    "y = df_2022_hit_into_play['RunValue']\n",
    "X1 = df_2023_hit_into_play[['launch_speed','launch_angle','hit_distance_sc']]\n",
    "y1 = df_2023_hit_into_play['RunValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have already split into X_train, y_train:\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "X_train_1, X_val_1, y_train_1, y_val_1 = train_test_split(X1_train, y1_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'alpha': 0.05,\n",
    "    'lambda': 0.5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor(**params)\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=False)\n",
    "xgb_model_1 = XGBRegressor(**params)\n",
    "xgb_model_1.fit(X1_train, y1_train, eval_set=[(X_val_1, y_val_1)], early_stopping_rounds=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "n_estimators = 10  # Number of XGBoost models in the ensemble\n",
    "predictions = []\n",
    "\n",
    "# 1. Create bootstrap samples and train XGBoost models\n",
    "for i in range(n_estimators):\n",
    "    X_train_sample, y_train_sample = resample(X_train, y_train)\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train_sample, y_train_sample, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=False)\n",
    "    \n",
    "    # 2. Predict on validation set\n",
    "    preds = model.predict(X_val)\n",
    "    predictions.append(preds)\n",
    "\n",
    "# 3. Average predictions from all models for ensemble prediction\n",
    "ensemble_preds = np.mean(predictions, axis=0)\n",
    "\n",
    "# Calculate R^2 for ensemble prediction\n",
    "ensemble_r2 = r2_score(y_val, ensemble_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49774610651139495"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = xgb.cv(\n",
    "    dtrain=dtrain, \n",
    "    params=params, \n",
    "    nfold=5, \n",
    "    num_boost_round=200, \n",
    "    early_stopping_rounds=10, \n",
    "    metrics=\"rmse\",\n",
    "    as_pandas=True, \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xRun Value EV/LA Best  R^2: -0.61678188005002909655\n"
     ]
    }
   ],
   "source": [
    "#Variance \n",
    "variance_y = y_train.var()\n",
    "best_r_squared = 1 - (cv_results['test-rmse-mean'].min() ** 2) / variance_y\n",
    "#print best r^2 without using scientific notation\n",
    "print('xRun Value EV/LA Best  R^2:', '{:.20f}'.format(best_r_squared))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022_hit_into_play['RunValue'] = xgb_model.predict(df_2022_hit_into_play[['launch_speed','launch_angle','hit_distance_sc']])\n",
    "df_2023_hit_into_play['RunValue'] = xgb_model_1.predict(df_2023_hit_into_play[['launch_speed','launch_angle','hit_distance_sc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine df_2022_hit_into_play and df_not_hit_into_play \n",
    "df_2022_1 = pd.concat([df_2022_hit_into_play,df_not_hit_into_play ],ignore_index=True)\n",
    "df_2023_1 = pd.concat([df_2023_hit_into_play,df_not_hit_into_play_2023 ],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = df_2022_1\n",
    "df_2023 = df_2023_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023['TaggedPitchType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any Nan RunValue\n",
    "df_2022 = df_2022[df_2022['RunValue'].notna()]\n",
    "df_2023 = df_2023[df_2023['RunValue'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change pitch type to match trackman data\n",
    "#FF, SI, FS,FA  = Fastball\n",
    "df_2022['TaggedPitchType'] = df_2022['TaggedPitchType'].replace(['FF','FA'],'Fastball')\n",
    "df_2023['TaggedPitchType'] = df_2023['TaggedPitchType'].replace(['FF','FA'],'Fastball')\n",
    "\n",
    "df_2022['TaggedPitchType'] = df_2022['TaggedPitchType'].replace(['SI'], 'Sinker')\n",
    "df_2023['TaggedPitchType'] = df_2023['TaggedPitchType'].replace(['SI'], 'Sinker')\n",
    "\n",
    "#SL,ST,FC  = Slider\n",
    "df_2022['TaggedPitchType'] = df_2022['TaggedPitchType'].replace(['SL'],'Slider')\n",
    "df_2023['TaggedPitchType'] = df_2023['TaggedPitchType'].replace(['SL'],'Slider')\n",
    "\n",
    "df_2022['TaggedPitchType'] = df_2022['TaggedPitchType'].replace(['ST'],'Sweeper')\n",
    "df_2023['TaggedPitchType'] = df_2023['TaggedPitchType'].replace(['ST'],'Sweeper')\n",
    "\n",
    "#CH, EP, SC, FO = ChangeUp\n",
    "df_2022['TaggedPitchType'] = df_2022['TaggedPitchType'].replace(['CH','EP','SC','FO','KN'],'ChangeUp')\n",
    "df_2023['TaggedPitchType'] = df_2023['TaggedPitchType'].replace(['CH','EP','SC','FO','KN'],'ChangeUp')\n",
    "#SV, CU, KC = Curveball\n",
    "df_2022['TaggedPitchType'] = df_2022['TaggedPitchType'].replace(['SV','CU','KC'],'Curveball')\n",
    "df_2023['TaggedPitchType'] = df_2023['TaggedPitchType'].replace(['SV','CU','KC'],'Curveball')\n",
    "#'FC' = Cutter\n",
    "df_2022['TaggedPitchType'] = df_2022['TaggedPitchType'].replace(['FC'],'Cutter')\n",
    "df_2023['TaggedPitchType'] = df_2023['TaggedPitchType'].replace(['FC'],'Cutter')\n",
    "#SPL = FS\n",
    "df_2022['TaggedPitchType'] = df_2022['TaggedPitchType'].replace(['FS'],'Splitter')\n",
    "df_2023['TaggedPitchType'] = df_2023['TaggedPitchType'].replace(['FS'],'Splitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022['ABS_Horizontal'] = abs(df_2022['HorzBreak'])\n",
    "df_2023['ABS_Horizontal'] = abs(df_2023['HorzBreak'])\n",
    "df_2022['ABS_RelSide'] = abs(df_2022['RelSide'])\n",
    "df_2023['ABS_RelSide'] = abs(df_2023['RelSide'])\n",
    "df_2022['differential_break'] = abs(df_2022['InducedVertBreak'] - df_2022['ABS_Horizontal'])\n",
    "df_2023['differential_break'] = abs(df_2023['InducedVertBreak'] - df_2023['ABS_Horizontal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastballs = 'Fastball', 'Sinker', 'TwoSeamFastBall', 'FourSeamFastBall', 'OneSeamFastBall'\n",
    "dfb2 = df_2022[df_2022.TaggedPitchType.isin(['Fastball', 'FourSeamFastball', 'OneSeamFastBall'])]\n",
    "dfb3 = df_2023[df_2023.TaggedPitchType.isin(['Fastball', 'FourSeamFastball', 'OneSeamFastBall'])]\n",
    "#'Sinker', 'TwoSeamFastBall',\n",
    "dsi2 = df_2022[df_2022.TaggedPitchType.isin(['Sinker', 'TwoSeamFastBall'])]\n",
    "dsi3 = df_2023[df_2023.TaggedPitchType.isin(['Sinker', 'TwoSeamFastBall'])]\n",
    "#sliders = 'Slider', 'Cutter'\n",
    "dsl2 = df_2022[df_2022.TaggedPitchType.isin(['Slider'])]\n",
    "dsl3 = df_2023[df_2023.TaggedPitchType.isin(['Slider'])]\n",
    "#Sweeper\n",
    "dst2 = df_2022[df_2022.TaggedPitchType.isin(['Sweeper'])]\n",
    "dst3 = df_2023[df_2023.TaggedPitchType.isin(['Sweeper'])]\n",
    "#curveballs = 'Curveball', 'KnuckleCurve'\n",
    "dcb2 = df_2022[df_2022.TaggedPitchType.isin(['Curveball', 'KnuckleCurve'])]\n",
    "dcb3 = df_2023[df_2023.TaggedPitchType.isin(['Curveball', 'KnuckleCurve'])]\n",
    "#changeups = 'Changeup', 'Splitter', 'Forkball', 'Screwball'\n",
    "dch2 = df_2022[df_2022.TaggedPitchType.isin(['ChangeUp'])]\n",
    "dch3 = df_2023[df_2023.TaggedPitchType.isin(['ChangeUp'])]\n",
    "#cutters = 'Cutter'\n",
    "dct2 = df_2022[df_2022.TaggedPitchType.isin(['Cutter'])]\n",
    "dct3 = df_2023[df_2023.TaggedPitchType.isin(['Cutter'])]\n",
    "#splitter\n",
    "dsp2 = df_2022[df_2022.TaggedPitchType.isin(['Splitter'])]\n",
    "dsp3 = df_2023[df_2023.TaggedPitchType.isin(['Splitter'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all rows with nan values\n",
    "dfb2 = dfb2.dropna()\n",
    "dsi2 = dsi2.dropna()\n",
    "dsl2 = dsl2.dropna()\n",
    "dst2 = dst2.dropna()\n",
    "dcb2 = dcb2.dropna()\n",
    "dch2 = dch2.dropna()\n",
    "dct2 = dct2.dropna()\n",
    "dsp2 = dsp2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xRV stuff\n",
    "X = dfb2[['RelSpeed','SpinRate','differential_break','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y = dfb2['RunValue']\n",
    "X1 = dsi2[['RelSpeed','SpinRate','differential_break','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y1 = dsi2['RunValue']\n",
    "X2 = dsl2[['RelSpeed','SpinRate','InducedVertBreak','ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y2 = dsl2['RunValue']\n",
    "X3 = dst2[['RelSpeed','SpinRate','InducedVertBreak','ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y3 = dst2['RunValue']\n",
    "X4 = dcb2[['RelSpeed','SpinRate','InducedVertBreak','ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y4 = dcb2['RunValue']\n",
    "X5 = dch2[['RelSpeed','SpinRate','InducedVertBreak','ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y5 = dch2['RunValue']\n",
    "X6 = dct2[['RelSpeed','SpinRate','InducedVertBreak','ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y6 = dct2['RunValue']\n",
    "X7 = dsp2[['RelSpeed','SpinRate','InducedVertBreak','ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y7 = dsp2['RunValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.25, random_state=101)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.25, random_state=101)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.25, random_state=101)\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.25, random_state=101)\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, test_size=0.25, random_state=101)\n",
    "\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(X6, y6, test_size=0.25, random_state=101)\n",
    "\n",
    "X7_train, X7_test, y7_train, y7_test = train_test_split(X7, y7, test_size=0.25, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'alpha': 0.05,\n",
    "    'lambda': 0.5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "\n",
    "xgb_model_0 = XGBRegressor(**params)\n",
    "xgb_model_0.fit(X_train, y_train)\n",
    "\n",
    "#sinker\n",
    "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.2, random_state=42)\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'alpha': 0.05,\n",
    "    'lambda': 0.5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "\n",
    "xgb_model1 = XGBRegressor(**params)\n",
    "xgb_model1.fit(X1_train, y1_train)\n",
    "\n",
    "#cslider\n",
    "X2_train, X2_val, y2_train, y2_val = train_test_split(X2_train, y2_train, test_size=0.2, random_state=42)\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'alpha': 0.05,\n",
    "    'lambda': 0.5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "xgb_model_2 = XGBRegressor(**params)\n",
    "xgb_model_2.fit(X2_train, y2_train)\n",
    "\n",
    "#csweeper\n",
    "X3_train, X3_val, y3_train, y3_val = train_test_split(X3_train, y3_train, test_size=0.2, random_state=42)\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'alpha': 0.05,\n",
    "    'lambda': 0.5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "xgb_model_3 = XGBRegressor(**params)\n",
    "xgb_model_3.fit(X3_train, y3_train)\n",
    "\n",
    "#curveball\n",
    "X4_train, X4_val, y4_train, y4_val = train_test_split(X4_train, y4_train, test_size=0.2, random_state=42)\n",
    "params = {\n",
    "    'max_depth': 5, \n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'alpha': 0.05,\n",
    "    'lambda': 0.5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "xgb_model_4 = XGBRegressor(**params)\n",
    "xgb_model_4.fit(X4_train, y4_train)\n",
    "\n",
    "#changeup \n",
    "X5_train, X5_val, y5_train, y5_val = train_test_split(X5_train, y5_train, test_size=0.2, random_state=42)\n",
    "params = {\n",
    "    'max_depth': 5, \n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'alpha': 0.05,\n",
    "    'lambda': 0.5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "xgb_model_5 = XGBRegressor(**params)\n",
    "xgb_model_5.fit(X5_train, y5_train)\n",
    "\n",
    "#cutter\n",
    "X6_train, X6_val, y6_train, y6_val = train_test_split(X6_train, y6_train, test_size=0.2, random_state=42)\n",
    "params = {\n",
    "    'max_depth': 5, \n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'alpha': 0.05,\n",
    "    'lambda': 0.5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "xgb_model_6 = XGBRegressor(**params)\n",
    "xgb_model_6.fit(X6_train, y6_train)\n",
    "\n",
    "#splitter\n",
    "X7_train, X7_val, y7_train, y7_val = train_test_split(X7_train, y7_train, test_size=0.2, random_state=42)\n",
    "params = {\n",
    "    'max_depth': 5, \n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'alpha': 0.05,\n",
    "    'lambda': 0.5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "xgb_model_7 = XGBRegressor(**params)\n",
    "xgb_model_7.fit(X7_train, y7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb2['xRV_xgb']= xgb_model_0.predict(dfb2[['RelSpeed','SpinRate','differential_break','RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dsi2['xRV_xgb']= xgb_model1.predict(dsi2[['RelSpeed','SpinRate','differential_break','RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dsl2['xRV_xgb']= xgb_model_2.predict(dsl2[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dst2['xRV_xgb']= xgb_model_3.predict(dst2[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dcb2['xRV_xgb']= xgb_model_4.predict(dcb2[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dch2['xRV_xgb']= xgb_model_5.predict(dch2[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dct2['xRV_xgb']= xgb_model_6.predict(dct2[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dsp2['xRV_xgb']= xgb_model_7.predict(dsp2[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb3['xRV_xgb']= xgb_model_0.predict(dfb3[['RelSpeed','SpinRate','differential_break','RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dsi3['xRV_xgb']= xgb_model1.predict(dsi3[['RelSpeed','SpinRate','differential_break','RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dsl3['xRV_xgb']= xgb_model_2.predict(dsl3[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dst3['xRV_xgb']= xgb_model_3.predict(dst3[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dcb3['xRV_xgb']= xgb_model_4.predict(dcb3[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dch3['xRV_xgb']= xgb_model_5.predict(dch3[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dct3['xRV_xgb']= xgb_model_6.predict(dct3[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])\n",
    "dsp3['xRV_xgb']= xgb_model_7.predict(dsp3[['RelSpeed', 'SpinRate','InducedVertBreak', 'ABS_Horizontal', 'RelHeight', 'ABS_RelSide', 'Extension']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the r^2 for all the variables\n",
    "#create the FB expected whiff rate\n",
    "X = dfb2[['xRV_xgb']]\n",
    "y = dfb2['RunValue']\n",
    "X2 = dsi2[['xRV_xgb']]\n",
    "y2 = dsi2['RunValue']\n",
    "X3 = dsl2[['xRV_xgb']]\n",
    "y3 = dsl2['RunValue']\n",
    "X4 = dst2[['xRV_xgb']]\n",
    "y4 = dst2['RunValue']\n",
    "X5 = dcb2[['xRV_xgb']]\n",
    "y5 = dcb2['RunValue']\n",
    "X6 = dch2[['xRV_xgb']]\n",
    "y6 = dch2['RunValue']\n",
    "X7 = dct2[['xRV_xgb']]\n",
    "y7 = dct2['RunValue']\n",
    "X8 = dsp2[['xRV_xgb']]\n",
    "y8 = dsp2['RunValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb2_max = dfb2['xRV_xgb'].max()\n",
    "dsi2_max = dsi2['xRV_xgb'].max()\n",
    "dsl2_max = dsl2['xRV_xgb'].max()\n",
    "dst2_max = dst2['xRV_xgb'].max()\n",
    "dcb2_max = dcb2['xRV_xgb'].max()\n",
    "dch2_max = dch2['xRV_xgb'].max()\n",
    "dct2_max = dct2['xRV_xgb'].max()\n",
    "dsp2_max = dsp2['xRV_xgb'].max()\n",
    "dfb3_max = dfb3['xRV_xgb'].max()\n",
    "dsi3_max = dsi3['xRV_xgb'].max()\n",
    "dsl3_max = dsl3['xRV_xgb'].max()\n",
    "dst3_max = dst3['xRV_xgb'].max()\n",
    "dcb3_max = dcb3['xRV_xgb'].max()\n",
    "dch3_max = dch3['xRV_xgb'].max()\n",
    "dct3_max = dct3['xRV_xgb'].max()\n",
    "dsp3_max = dsp3['xRV_xgb'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled \n",
    "dfb2['xRV_Scaled'] = dfb2['xRV_xgb'] - dfb2_max\n",
    "dfb2['xRV/100_stuff_scaled_abs'] = abs(dfb2['xRV_Scaled'])\n",
    "dfb2['Stuff_plus'] = dfb2['xRV/100_stuff_scaled_abs'] / dfb2['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "dfb3['xRV_Scaled'] = dfb3['xRV_xgb'] - dfb3_max\n",
    "dfb3['xRV/100_stuff_scaled_abs'] = abs(dfb3['xRV_Scaled'])\n",
    "dfb3['Stuff_plus'] = dfb3['xRV/100_stuff_scaled_abs'] / dfb3['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "\n",
    "#scaled \n",
    "dsi2['xRV_Scaled'] = dsi2['xRV_xgb'] - dsi2_max\n",
    "dsi2['xRV/100_stuff_scaled_abs'] = abs(dsi2['xRV_Scaled'])\n",
    "dsi2['Stuff_plus'] = dsi2['xRV/100_stuff_scaled_abs'] / dsi2['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "dsi3['xRV_Scaled'] = dsi3['xRV_xgb'] - dsi3_max\n",
    "dsi3['xRV/100_stuff_scaled_abs'] = abs(dsi3['xRV_Scaled'])\n",
    "dsi3['Stuff_plus'] = dsi3['xRV/100_stuff_scaled_abs'] / dsi3['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "\n",
    "#scaled \n",
    "dsl2['xRV_Scaled'] = dsl2['xRV_xgb'] - dfb2_max\n",
    "dsl2['xRV/100_stuff_scaled_abs'] = abs(dsl2['xRV_Scaled'])\n",
    "dsl2['Stuff_plus'] = dsl2['xRV/100_stuff_scaled_abs'] / dsl2['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "dsl3['xRV_Scaled'] = dsl3['xRV_xgb'] - dsl3_max\n",
    "dsl3['xRV/100_stuff_scaled_abs'] = abs(dsl3['xRV_Scaled'])\n",
    "dsl3['Stuff_plus'] = dsl3['xRV/100_stuff_scaled_abs'] / dsl3['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "\n",
    "#scaled \n",
    "dst2['xRV_Scaled'] = dst2['xRV_xgb'] - dst2_max\n",
    "dst2['xRV/100_stuff_scaled_abs'] = abs(dst2['xRV_Scaled'])\n",
    "dst2['Stuff_plus'] = dst2['xRV/100_stuff_scaled_abs'] / dst2['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "dst3['xRV_Scaled'] = dst3['xRV_xgb'] - dst3_max\n",
    "dst3['xRV/100_stuff_scaled_abs'] = abs(dst3['xRV_Scaled'])\n",
    "dst3['Stuff_plus'] = dst3['xRV/100_stuff_scaled_abs'] / dst3['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "\n",
    "#scaled \n",
    "dcb2['xRV_Scaled'] = dcb2['xRV_xgb'] - dcb2_max\n",
    "dcb2['xRV/100_stuff_scaled_abs'] = abs(dcb2['xRV_Scaled'])\n",
    "dcb2['Stuff_plus'] = dcb2['xRV/100_stuff_scaled_abs'] / dcb2['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "dcb3['xRV_Scaled'] = dcb3['xRV_xgb'] - dcb3_max\n",
    "dcb3['xRV/100_stuff_scaled_abs'] = abs(dcb3['xRV_Scaled'])\n",
    "dcb3['Stuff_plus'] = dcb3['xRV/100_stuff_scaled_abs'] / dcb3['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "\n",
    "#scaled \n",
    "dch2['xRV_Scaled'] = dch2['xRV_xgb'] - dch2_max\n",
    "dch2['xRV/100_stuff_scaled_abs'] = abs(dch2['xRV_Scaled'])\n",
    "dch2['Stuff_plus'] = dch2['xRV/100_stuff_scaled_abs'] / dch2['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "dch3['xRV_Scaled'] = dch3['xRV_xgb'] - dch3_max\n",
    "dch3['xRV/100_stuff_scaled_abs'] = abs(dch3['xRV_Scaled'])\n",
    "dch3['Stuff_plus'] = dch3['xRV/100_stuff_scaled_abs'] / dch3['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "\n",
    "#scaled \n",
    "dct2['xRV_Scaled'] = dct2['xRV_xgb'] - dct2_max\n",
    "dct2['xRV/100_stuff_scaled_abs'] = abs(dct2['xRV_Scaled'])\n",
    "dct2['Stuff_plus'] = dct2['xRV/100_stuff_scaled_abs'] / dct2['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "dct3['xRV_Scaled'] = dct3['xRV_xgb'] - dct3_max\n",
    "dct3['xRV/100_stuff_scaled_abs'] = abs(dct3['xRV_Scaled'])\n",
    "dct3['Stuff_plus'] = dct3['xRV/100_stuff_scaled_abs'] / dct3['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "\n",
    "#splitter\n",
    "dsp2['xRV_Scaled'] = dsp2['xRV_xgb'] - dsp2_max\n",
    "dsp2['xRV/100_stuff_scaled_abs'] = abs(dsp2['xRV_Scaled'])\n",
    "dsp2['Stuff_plus'] = dsp2['xRV/100_stuff_scaled_abs'] / dsp2['xRV/100_stuff_scaled_abs'].mean() * 100\n",
    "dsp3['xRV_Scaled'] = dsp3['xRV_xgb'] - dsp3_max\n",
    "dsp3['xRV/100_stuff_scaled_abs'] = abs(dsp3['xRV_Scaled'])\n",
    "dsp3['Stuff_plus'] = dsp3['xRV/100_stuff_scaled_abs'] / dsp3['xRV/100_stuff_scaled_abs'].mean() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming df_total is your DataFrame and 'Stuff_plus' is the name of your column\n",
    "current_std_fb = dfb3['Stuff_plus'].std()\n",
    "\n",
    "# Determine the scaling factor needed to adjust the standard deviation to 10\n",
    "desired_std = 10\n",
    "scaling_factor = desired_std / current_std_fb\n",
    "\n",
    "# Apply the scaling factor to each value in the column\n",
    "# Subtract the mean, scale the zero-mean data, and then add the original mean back\n",
    "mean = dfb3['Stuff_plus'].mean()\n",
    "dfb3['Final_Adjusted_Stuff_Plus'] = ((dfb3['Stuff_plus'] - mean) * scaling_factor) + mean\n",
    "\n",
    "# Verify the transformation by calculating the new standard deviation and mean\n",
    "new_std = dfb3['Final_Adjusted_Stuff_Plus'].std()\n",
    "new_mean = dfb3['Final_Adjusted_Stuff_Plus'].mean()\n",
    "\n",
    "current_std_si = dsi3['Stuff_plus'].std()\n",
    "\n",
    "# Determine the scaling factor needed to adjust the standard deviation to 10\n",
    "desired_std = 10\n",
    "scaling_factor = desired_std / current_std_si\n",
    "\n",
    "# Apply the scaling factor to each value in the column\n",
    "# Subtract the mean, scale the zero-mean data, and then add the original mean back\n",
    "mean = dsi3['Stuff_plus'].mean()\n",
    "dsi3['Final_Adjusted_Stuff_Plus'] = ((dsi3['Stuff_plus'] - mean) * scaling_factor) + mean\n",
    "\n",
    "# Verify the transformation by calculating the new standard deviation and mean\n",
    "new_std = dsi3['Final_Adjusted_Stuff_Plus'].std()\n",
    "new_mean = dsi3['Final_Adjusted_Stuff_Plus'].mean()\n",
    "\n",
    "current_std_sl = dsl3['Stuff_plus'].std()\n",
    "\n",
    "# Determine the scaling factor needed to adjust the standard deviation to 10\n",
    "desired_std = 10\n",
    "scaling_factor = desired_std / current_std_sl\n",
    "\n",
    "# Apply the scaling factor to each value in the column\n",
    "# Subtract the mean, scale the zero-mean data, and then add the original mean back\n",
    "mean = dsl3['Stuff_plus'].mean()\n",
    "dsl3['Final_Adjusted_Stuff_Plus'] = ((dsl3['Stuff_plus'] - mean) * scaling_factor) + mean\n",
    "\n",
    "# Verify the transformation by calculating the new standard deviation and mean\n",
    "new_std = dsl3['Final_Adjusted_Stuff_Plus'].std()\n",
    "new_mean = dsl3['Final_Adjusted_Stuff_Plus'].mean()\n",
    "\n",
    "current_std_st = dst3['Stuff_plus'].std()\n",
    "\n",
    "# Determine the scaling factor needed to adjust the standard deviation to 10\n",
    "desired_std = 10\n",
    "scaling_factor = desired_std / current_std_st\n",
    "\n",
    "# Apply the scaling factor to each value in the column\n",
    "# Subtract the mean, scale the zero-mean data, and then add the original mean back\n",
    "mean = dst3['Stuff_plus'].mean()\n",
    "dst3['Final_Adjusted_Stuff_Plus'] = ((dst3['Stuff_plus'] - mean) * scaling_factor) + mean\n",
    "\n",
    "# Verify the transformation by calculating the new standard deviation and mean\n",
    "new_std = dst3['Final_Adjusted_Stuff_Plus'].std()\n",
    "new_mean = dst3['Final_Adjusted_Stuff_Plus'].mean()\n",
    "\n",
    "current_std_cb = dcb3['Stuff_plus'].std()\n",
    "\n",
    "# Determine the scaling factor needed to adjust the standard deviation to 10\n",
    "desired_std = 10\n",
    "scaling_factor = desired_std / current_std_cb\n",
    "\n",
    "# Apply the scaling factor to each value in the column\n",
    "# Subtract the mean, scale the zero-mean data, and then add the original mean back\n",
    "mean = dcb3['Stuff_plus'].mean()\n",
    "dcb3['Final_Adjusted_Stuff_Plus'] = ((dcb3['Stuff_plus'] - mean) * scaling_factor) + mean\n",
    "\n",
    "# Verify the transformation by calculating the new standard deviation and mean\n",
    "new_std = dcb3['Final_Adjusted_Stuff_Plus'].std()\n",
    "new_mean = dcb3['Final_Adjusted_Stuff_Plus'].mean()\n",
    "\n",
    "current_std_ch = dch3['Stuff_plus'].std()\n",
    "\n",
    "# Determine the scaling factor needed to adjust the standard deviation to 10\n",
    "desired_std = 10\n",
    "scaling_factor = desired_std / current_std_ch\n",
    "\n",
    "# Apply the scaling factor to each value in the column\n",
    "# Subtract the mean, scale the zero-mean data, and then add the original mean back\n",
    "mean = dch3['Stuff_plus'].mean()\n",
    "dch3['Final_Adjusted_Stuff_Plus'] = ((dch3['Stuff_plus'] - mean) * scaling_factor) + mean\n",
    "\n",
    "# Verify the transformation by calculating the new standard deviation and mean\n",
    "new_std = dch3['Final_Adjusted_Stuff_Plus'].std()\n",
    "new_mean = dch3['Final_Adjusted_Stuff_Plus'].mean()\n",
    "\n",
    "current_std_ct = dct3['Stuff_plus'].std()\n",
    "\n",
    "# Determine the scaling factor needed to adjust the standard deviation to 10\n",
    "desired_std = 10\n",
    "scaling_factor = desired_std / current_std_ch\n",
    "\n",
    "# Apply the scaling factor to each value in the column\n",
    "# Subtract the mean, scale the zero-mean data, and then add the original mean back\n",
    "mean = dct3['Stuff_plus'].mean()\n",
    "dct3['Final_Adjusted_Stuff_Plus'] = ((dct3['Stuff_plus'] - mean) * scaling_factor) + mean\n",
    "\n",
    "# Verify the transformation by calculating the new standard deviation and mean\n",
    "new_std = dct3['Final_Adjusted_Stuff_Plus'].std()\n",
    "new_mean = dct3['Final_Adjusted_Stuff_Plus'].mean()\n",
    "\n",
    "#splitter\n",
    "current_std_sp = dsp3['Stuff_plus'].std()\n",
    "\n",
    "# Determine the scaling factor needed to adjust the standard deviation to 10\n",
    "desired_std = 10\n",
    "scaling_factor = desired_std / current_std_sp\n",
    "\n",
    "# Apply the scaling factor to each value in the column\n",
    "# Subtract the mean, scale the zero-mean data, and then add the original mean back\n",
    "mean = dsp3['Stuff_plus'].mean()\n",
    "dsp3['Final_Adjusted_Stuff_Plus'] = ((dsp3['Stuff_plus'] - mean) * scaling_factor) + mean\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the dataframes\n",
    "df_2022 = pd.concat([dfb2, dsi2, dsl2, dst2, dcb2, dch2, dct2], ignore_index=True)\n",
    "df_2023_total = pd.concat([dfb3, dsi3, dsl3, dst3, dcb3, dch3, dct3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby pitcher and TaggedPitchType\n",
    "df_2023_total_pitch_RV = df_2023_total.groupby(['Pitcher', 'TaggedPitchType']).agg({'RelSpeed': 'mean','InducedVertBreak':'mean','HorzBreak':'mean','Final_Adjusted_Stuff_Plus': 'mean', 'RunValue': 'sum', 'launch_speed':'mean' }).reset_index()\n",
    "df_2023_total_pitcher_RV = df_2023_total.groupby(['Pitcher']).agg({'Final_Adjusted_Stuff_Plus': 'mean', 'RunValue': 'sum', 'launch_speed':'mean' }).reset_index()\n",
    "df_2023_total_pitcher_RV['Count'] = df_2023_total.groupby(['Pitcher']).size().reset_index(name='Count')['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Stuff+ R^2: 0.09287529754079704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#calculate the r^2 of Final_Adjusted_Stuff_Plus on RunValue\n",
    "X = df_2023_total_pitcher_RV[['Final_Adjusted_Stuff_Plus']]\n",
    "y = df_2023_total_pitcher_RV['RunValue']\n",
    "#linear regression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "#predict\n",
    "y_pred = lm.predict(X)\n",
    "#r^2\n",
    "r2 = r2_score(y, y_pred)\n",
    "print('Unweighted Stuff+ R^2:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player = pd.read_csv('/Users/johndavis/Desktop/PitcherTeam.csv')\n",
    "df_player.rename(columns = {'player_name':'Pitcher', 'PitcherTeam':'Team'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023_total['Team'] = df_2023_total['Pitcher'].map(df_player.set_index('Pitcher')['Team'])\n",
    "df_2023_total_pitch_RV['Team'] = df_2023_total_pitch_RV['Pitcher'].map(df_player.set_index('Pitcher')['Team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023_total_pitcher_RV.rename(columns = {'Pitcher':'Name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ERA = pd.read_csv('/Users/johndavis/Desktop/2023_ERA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final_Adjusted_Stuff_Plus</th>\n",
       "      <th>RunValue</th>\n",
       "      <th>launch_speed</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Final_Adjusted_Stuff_Plus</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.304754</td>\n",
       "      <td>-0.184984</td>\n",
       "      <td>0.161421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunValue</th>\n",
       "      <td>-0.304754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207878</td>\n",
       "      <td>-0.155659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launch_speed</th>\n",
       "      <td>-0.184984</td>\n",
       "      <td>0.207878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.095513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>0.161421</td>\n",
       "      <td>-0.155659</td>\n",
       "      <td>-0.095513</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Final_Adjusted_Stuff_Plus  RunValue  launch_speed  \\\n",
       "Final_Adjusted_Stuff_Plus                   1.000000 -0.304754     -0.184984   \n",
       "RunValue                                   -0.304754  1.000000      0.207878   \n",
       "launch_speed                               -0.184984  0.207878      1.000000   \n",
       "Count                                       0.161421 -0.155659     -0.095513   \n",
       "\n",
       "                              Count  \n",
       "Final_Adjusted_Stuff_Plus  0.161421  \n",
       "RunValue                  -0.155659  \n",
       "launch_speed              -0.095513  \n",
       "Count                      1.000000  "
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flip names so they match first and last name instead of last, first\n",
    "df_2023_total_pitcher_RV['Name'] = df_2023_total_pitcher_RV['Name'].str.split(', ').str[::-1].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the ERA and the RunValue\n",
    "df_2023_total_pitcher_RV_ERA = df_2023_total_pitcher_RV.merge(df_ERA, on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE SO\tuBB\tHBP\tHR\t\n",
    "del df_2023_total_pitcher_RV_ERA['SO']\n",
    "del df_2023_total_pitcher_RV_ERA['uBB']\n",
    "del df_2023_total_pitcher_RV_ERA['HBP']\n",
    "del df_2023_total_pitcher_RV_ERA['HR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023_total_pitcher_RV_ERA_count_4 = df_2023_total_pitcher_RV_ERA[df_2023_total_pitcher_RV_ERA['Count'] > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary for 2023 Season\n",
      "*************\n",
      "Full Arsenal || 250 Pitch Minimum\n",
      "*************\n",
      "Stuff+ Model R^2: 0.20912971769733735\n",
      "Descriptive Correlation between Stuff+ and ERA: -0.34188257295111313\n",
      "Descriptive Correlation between Stuff+ and FIP: -0.348328740889808\n",
      "Descriptive Correlation between Stuff+ and wOBA_against: -0.3710634395432807\n"
     ]
    }
   ],
   "source": [
    "#calculate the r^2 of Final_Adjusted_Stuff_Plus on RunValue\n",
    "X = df_2023_total_pitcher_RV_ERA_count_1[['Final_Adjusted_Stuff_Plus']]\n",
    "y = df_2023_total_pitcher_RV_ERA_count_1['RunValue']\n",
    "\n",
    "#linear regression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "#predict\n",
    "y_pred = lm.predict(X)\n",
    "#r^2\n",
    "r2 = r2_score(y, y_pred)\n",
    "print('Model Summary for 2023 Season')\n",
    "print('*************')\n",
    "print('Full Arsenal || 250 Pitch Minimum')\n",
    "print('*************')\n",
    "print('Stuff+ Model R^2:', r2)\n",
    "#print the correlation between Final_Adjusted_Stuff_Plus and ERA / Final_Adjusted_Stuff_Plus and FIP / Final_Adjusted_Stuff_Plus and wOBA_against\t\n",
    "print('Descriptive Correlation between Stuff+ and ERA:', df_2023_total_pitcher_RV_ERA_count_1['Final_Adjusted_Stuff_Plus'].corr(df_2023_total_pitcher_RV_ERA_count_1['ERA']))\n",
    "print('Descriptive Correlation between Stuff+ and FIP:', df_2023_total_pitcher_RV_ERA_count_1['Final_Adjusted_Stuff_Plus'].corr(df_2023_total_pitcher_RV_ERA_count_1['FIP']))\n",
    "print('Descriptive Correlation between Stuff+ and wOBA_against:', df_2023_total_pitcher_RV_ERA_count_1['Final_Adjusted_Stuff_Plus'].corr(df_2023_total_pitcher_RV_ERA_count_1['wOBA_against']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary for 2023 Season\n",
      "*************\n",
      "Full Arsenal || 500 Pitch Minimum\n",
      "*************\n",
      "Stuff+ Model R^2: 0.22952074798863087\n",
      "Descriptive Correlation between Stuff+ and ERA: -0.3938126853115962\n",
      "Descriptive Correlation between Stuff+ and FIP: -0.3945330323447696\n",
      "Descriptive Correlation between Stuff+ and wOBA_against: -0.4282581540433598\n"
     ]
    }
   ],
   "source": [
    "#calculate the r^2 of Final_Adjusted_Stuff_Plus on RunValue\n",
    "X = df_2023_total_pitcher_RV_ERA_count[['Final_Adjusted_Stuff_Plus']]\n",
    "y = df_2023_total_pitcher_RV_ERA_count['RunValue']\n",
    "\n",
    "#linear regression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "#predict\n",
    "y_pred = lm.predict(X)\n",
    "#r^2\n",
    "r2 = r2_score(y, y_pred)\n",
    "print('Model Summary for 2023 Season')\n",
    "print('*************')\n",
    "print('Full Arsenal || 500 Pitch Minimum')\n",
    "print('*************')\n",
    "print('Stuff+ Model R^2:', r2)\n",
    "#print the correlation between Final_Adjusted_Stuff_Plus and ERA / Final_Adjusted_Stuff_Plus and FIP / Final_Adjusted_Stuff_Plus and wOBA_against\t\n",
    "print('Descriptive Correlation between Stuff+ and ERA:', df_2023_total_pitcher_RV_ERA_count['Final_Adjusted_Stuff_Plus'].corr(df_2023_total_pitcher_RV_ERA_count['ERA']))\n",
    "print('Descriptive Correlation between Stuff+ and FIP:', df_2023_total_pitcher_RV_ERA_count['Final_Adjusted_Stuff_Plus'].corr(df_2023_total_pitcher_RV_ERA_count['FIP']))\n",
    "print('Descriptive Correlation between Stuff+ and wOBA_against:', df_2023_total_pitcher_RV_ERA_count['Final_Adjusted_Stuff_Plus'].corr(df_2023_total_pitcher_RV_ERA_count['wOBA_against']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary for 2023 Season\n",
      "*************\n",
      "Full Arsenal || 1000 Pitch Minimum\n",
      "*************\n",
      "Stuff+ Model R^2: 0.258439850165034\n",
      "Descriptive Correlation between Stuff+ and ERA: -0.43462576397025826\n",
      "Descriptive Correlation between Stuff+ and FIP: -0.48210312243510767\n",
      "Descriptive Correlation between Stuff+ and wOBA_against: -0.48779034228651447\n"
     ]
    }
   ],
   "source": [
    "#calculate the r^2 of Final_Adjusted_Stuff_Plus on RunValue\n",
    "X = df_2023_total_pitcher_RV_ERA_count_4[['Final_Adjusted_Stuff_Plus']]\n",
    "y = df_2023_total_pitcher_RV_ERA_count_4['RunValue']\n",
    "\n",
    "#linear regression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "#predict\n",
    "y_pred = lm.predict(X)\n",
    "#r^2\n",
    "r2 = r2_score(y, y_pred)\n",
    "print('Model Summary for 2023 Season')\n",
    "print('*************')\n",
    "print('Full Arsenal || 1000 Pitch Minimum')\n",
    "print('*************')\n",
    "print('Stuff+ Model R^2:', r2)\n",
    "#print the correlation between Final_Adjusted_Stuff_Plus and ERA / Final_Adjusted_Stuff_Plus and FIP / Final_Adjusted_Stuff_Plus and wOBA_against\t\n",
    "print('Descriptive Correlation between Stuff+ and ERA:', df_2023_total_pitcher_RV_ERA_count_4['Final_Adjusted_Stuff_Plus'].corr(df_2023_total_pitcher_RV_ERA_count_4['ERA']))\n",
    "print('Descriptive Correlation between Stuff+ and FIP:', df_2023_total_pitcher_RV_ERA_count_4['Final_Adjusted_Stuff_Plus'].corr(df_2023_total_pitcher_RV_ERA_count_4['FIP']))\n",
    "print('Descriptive Correlation between Stuff+ and wOBA_against:', df_2023_total_pitcher_RV_ERA_count_4['Final_Adjusted_Stuff_Plus'].corr(df_2023_total_pitcher_RV_ERA_count_4['wOBA_against']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
